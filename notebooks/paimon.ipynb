{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.flinkextended::flink-scala-api:1.17.1_1.1.0`\n",
    "\n",
    "import org.apache.flinkx.api._\n",
    "import org.apache.flinkx.api.serializers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.flink:flink-table-api-java:1.17.1`\n",
    "import $ivy.`org.apache.flink:flink-table-api-java-bridge:1.17.1`\n",
    "import $ivy.`org.apache.flink:flink-table-planner-loader:1.17.1`\n",
    "import $ivy.`org.apache.flink:flink-table-runtime:1.17.1`\n",
    "\n",
    "import $ivy.`org.apache.flink:flink-clients:1.17.1`\n",
    "import $ivy.`org.apache.flink:flink-shaded-hadoop-2-uber:2.8.3-10.0`\n",
    "import $ivy.`org.apache.flink:flink-runtime-web:1.17.1`\n",
    "\n",
    "import $ivy.`org.slf4j:slf4j-log4j12:1.7.15`\n",
    "\n",
    "import $ivy.`org.apache.hadoop:hadoop-mapreduce-client-core:2.8.3`\n",
    "import $ivy.`org.apache.hadoop:hadoop-mapreduce-client-common:2.8.3`\n",
    "import $ivy.`org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.8.3`\n",
    "import $ivy.`org.apache.paimon:paimon-flink-1.17:0.5.0-incubating`\n",
    "\n",
    "import org.apache.flink.table.api.bridge.java.StreamTableEnvironment\n",
    "import org.apache.flink.table.api._\n",
    "import org.apache.flink.configuration.Configuration\n",
    "import org.apache.flink.configuration.ConfigConstants\n",
    "import org.apache.flink.configuration.RestOptions.BIND_PORT\n",
    "\n",
    "import scala.collection.JavaConverters._\n",
    "\n",
    "val config = Configuration.fromMap(\n",
    "  Map(\n",
    "    ConfigConstants.LOCAL_START_WEBSERVER -> \"true\",\n",
    "    BIND_PORT.key -> \"8082\",\n",
    "    \"execution.checkpointing.interval\" -> \"10 s\"\n",
    "  ).asJava\n",
    ")\n",
    "\n",
    "val env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(config)\n",
    "val tEnv = StreamTableEnvironment.create(env.getJavaEnv)\n",
    "val settings = EnvironmentSettings.newInstance().inStreamingMode()\n",
    "  .withConfiguration(env.getJavaEnv.getConfiguration.asInstanceOf[Configuration])\n",
    "  .build()\n",
    "val table = TableEnvironment.create(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFlinkSql(sql: String) = \n",
    "  sql.split(\";\").map(_.trim).filterNot(_.isEmpty).foreach { s => \n",
    "    println(s\"Executing: $s\")\n",
    "    table.executeSql(s).print\n",
    "  }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runFlinkSql(\"\"\"\n",
    "    CREATE CATALOG my_catalog WITH (\n",
    "        'type'='paimon',\n",
    "        'warehouse'='file:/tmp/paimon'\n",
    "    );\n",
    "    USE CATALOG my_catalog\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runFlinkSql(\"\"\"\n",
    "  use catalog my_catalog;\n",
    "  CREATE TEMPORARY TABLE word_table (\n",
    "    word STRING\n",
    "  ) WITH (\n",
    "    'connector' = 'datagen',\n",
    "    'fields.word.length' = '1'\n",
    "  )\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = table.executeSql(\"\"\"\n",
    "    INSERT INTO word_count\n",
    "    SELECT word, COUNT(*) FROM word_table GROUP BY word\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//import scala.jdk.OptionConverters._\n",
    "result.getJobClient().toScala.foreach(status => print(status.getJobStatus.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.getJobClient().toScala.foreach(_.cancel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.13)",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
